# Computer Vision And Generative AI

The Segment Anything Model (SAM) generates a mask around the specified object, selecting the most accurate one. The app allows users to change the background while keeping the subject or modify the subject while retaining the background. Users can accept the generated mask or refine it by adding more points. Once the mask is finalized, users input a text description (and optionally a negative prompt) to select a new background for the object. This background is created using a text-to-image diffusion model and displayed as the final result.


## Included in this repository 

* The code used starter.ipynb for this project image generated by Stable Diffusion through a text prompt
* This README.md file


## Results

![](https://github.com/1Px-Vision/Generative-AI/blob/main/Computer-Vision-and-Generative-AI-Project/Result_generative_AI.jpg)


* Showcase expertise in loading and utilizing the Segment Anything Model (SAM) for object segmentation.
* Demonstrate the ability to load a pre-trained **AutoPipelineForInpainting** from the diffusers library.
* Use the interactive app to illustrate how to run SAM for segmenting a subject and replacing the background or the subject itself using text prompts.







